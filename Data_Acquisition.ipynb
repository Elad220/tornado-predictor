{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable initialization\n",
    "ESWD_URL = 'https://eswd.eu/cgi-bin/eswd.cgi'\n",
    "# WIKI_URL = 'https://en.wikipedia.org/wiki/List_of_European_tornadoes_and_tornado_outbreaks'\n",
    "NOAA_URL = 'https://www.ncdc.noaa.gov/stormevents/choosedates.jsp?statefips=-999,ALL'\n",
    "ESWD_TORNADO_XPATH = '//*[@name=\"TORNADO\"]'\n",
    "YEARS_TO_COUNT = ['1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "MONTHS_TO_COUNT = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "START_DATE_XPATH = '//*[@id=\"start_date\"]'\n",
    "END_DATE_XPATH = '//*[@id=\"end_date\"]'\n",
    "FIND_REPORTS_COUNT_XPATH = \"//p[contains(text(),'selected reports')] | //p[contains(text(),'no reports')]\"\n",
    "SUBMIT_XPATH = '(//*[@value=\"submit query\"])[2]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilary functions for creating the web driver and closing it\n",
    "def create_web_driver():\n",
    "    return webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "def start_web_driver(driver, url):\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "\n",
    "def close_web_driver(driver):\n",
    "    driver.close()\n",
    "\n",
    "def log(message,filename):\n",
    "    with open(f'{filename}', 'a') as f:\n",
    "        f.write(message + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA_BEGINMONTH_XPATH = \"//select[@id='beginDate_mm']//option[@value='\"\n",
    "NOAA_BEGINYEAR_XPATH = \"//select[@id='beginDate_yyyy']//option[@value='\"\n",
    "NOAA_BEGINDAY_XPATH = \"//select[@id='beginDate_dd']//option[contains(text(),'01')]\"\n",
    "# NOAA_BEGINDAY_XPATH_CHOOSE = \n",
    "NOAA_ENDMONTH_XPATH = \"//select[@id='endDate_mm']//option[contains(text(),'\"\n",
    "NOAA_ENDYEAR_XPATH = \"//select[@id='endDate_yyyy']//option[contains(text(),'\"\n",
    "NOAA_ENDDAY_XPATH = \"//select[@id='endDate_dd']//option[contains(text(),'\"\n",
    "NOAA_EVENTTYPE_XPATH = \"//select[@id='eventType']//option[contains(@value,'Tornado')]\"\n",
    "NOAA_SEARCH_XPATH = \"//input[@value='Search']\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/elad/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1311800123.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  return webdriver.Chrome(ChromeDriverManager().install())\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDMONTH_XPATH}{end_month}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDMONTH_XPATH}{end_month}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDYEAR_XPATH}{curr_year}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDYEAR_XPATH}{curr_year}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDDAY_XPATH}{end_day}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/1393114960.py:12: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(f\"{NOAA_ENDDAY_XPATH}{end_day}')]\").click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/4091449940.py:18: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver_noaa.find_element_by_xpath(NOAA_BEGINDAY_XPATH).click()\n",
      "/var/folders/gm/0p8xp0qn071cptf2y2k3ly7h0000gn/T/ipykernel_49081/4091449940.py:19: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver_noaa.find_element_by_xpath(NOAA_BEGINDAY_XPATH).click()\n"
     ]
    }
   ],
   "source": [
    "noaa_base_xpath = \"//table[@id='results']//tr[position()>2 and position()<last()]\"\n",
    "noaa_city_xpath = \"/td[1]\"\n",
    "noaa_district_xpath = \"/td[2]\"\n",
    "noaa_date_xpath = \"/td[4]\"\n",
    "noaa_time_xpath = \"/td[5]\"\n",
    "noaa_scale_xpath = \"/td[8]\"\n",
    "noaa_deaths_xpath = \"/td[9]\"\n",
    "noaa_click_xpath = \"//td[1]//@href\"\n",
    "noaa_return_xpath = \"//a[@id='anch_8']/@href\"\n",
    "noaa_city_list, noaa_district_list, noaa_country_list, noaa_date_list, noaa_time_list, noaa_scale_list, noaa_deaths, noaa_length_list, noaa_width_list  = [], [], [], [], [], [], [] , [], []\n",
    "driver_noaa = create_web_driver()\n",
    "start_web_driver(driver_noaa, NOAA_URL)\n",
    "# noaa_locations = driver_noaa.find_elements_by_xpath()\n",
    "# noaa_report_count = len(noaa_locations)\n",
    "for year in YEARS_TO_COUNT:\n",
    "    for month in range(1,13,4):\n",
    "        noaa_click_end_date(driver_noaa, year, month+3)\n",
    "driver_noaa.find_element_by_xpath(NOAA_BEGINDAY_XPATH).click()\n",
    "driver_noaa.find_element_by_xpath(NOAA_BEGINDAY_XPATH).click()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to parse the relevant date and input it in the relevant fields of the web driver received by input_date\n",
    "def noaa_click_end_date(driver, curr_year, end_month):\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDMONTH_XPATH}{end_month}')]\").click()\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDMONTH_XPATH}{end_month}')]\").click()\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDYEAR_XPATH}{curr_year}')]\").click()\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDYEAR_XPATH}{curr_year}')]\").click()\n",
    "    if end_month == 4:\n",
    "        end_day = 30\n",
    "    else:\n",
    "        end_day = 31\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDDAY_XPATH}{end_day}')]\").click()\n",
    "    driver.find_element_by_xpath(f\"{NOAA_ENDDAY_XPATH}{end_day}')]\").click()\n",
    "    \n",
    "    \n",
    "def get_end_date(curr_year, curr_month):\n",
    "    if curr_month == '02':\n",
    "        day = '28'\n",
    "    elif curr_month == '04' or curr_month == '06' or curr_month == '09' or curr_month == '11':\n",
    "        day = '30'\n",
    "    else:\n",
    "        day = '31'\n",
    "    return f'{day}-{curr_month}-{curr_year}'\n",
    "\n",
    "def get_start_date(curr_year,curr_month):\n",
    "    return f'01-{curr_month}-{curr_year}'\n",
    "\n",
    "def input_date(driver, start_date, end_date, start_date_xpath, end_date_xpath):\n",
    "    driver.find_element_by_xpath(start_date_xpath).clear()\n",
    "    time.sleep(0.5)\n",
    "    driver.find_element_by_xpath(start_date_xpath).send_keys(start_date)\n",
    "    driver.find_element_by_xpath(end_date_xpath).clear()\n",
    "    time.sleep(0.5)\n",
    "    driver.find_element_by_xpath(end_date_xpath).send_keys(end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to accumulate the data from the site in lists to prepare for dataframe creation using other auxilary functions\n",
    "def get_data_from_page(driver,year,district, city, country, coordinates, date, times, scale,length,years):\n",
    "    base_xpath =\"//td[@class='base_info']/p[b and not(@class='smallgray')]\"\n",
    "    district_xpath = \"/b[1]\"\n",
    "    bold_tags_xpath = \"/b\"\n",
    "    country_xpath = \"/b[2]\"\n",
    "    date_xpath = \"/b[3]\"\n",
    "    time_xpath = \"/b[4]\"\n",
    "    scale_xpath_1 = \"(//p[@class='TORNADO detail_info_entry'])\"\n",
    "    scale_xpath_2 = \"/b[contains(text(),'F')]\" \n",
    "    scale_xpath_3 = \"((//p[@class='TORNADO'][contains(b,'tornado')])\"\n",
    "    scale_xpath_4 = \"/b[text()='tornado'])\"\n",
    "    reports_count = len(driver.find_elements_by_xpath(base_xpath))\n",
    "    len_elements = driver.find_elements_by_xpath(scale_xpath_1)\n",
    "    parent_items= driver.find_elements_by_xpath(base_xpath)\n",
    "    for i in range(reports_count):\n",
    "        years.append(year)\n",
    "        district = get_elements_from_list(driver,district_xpath,base_xpath,district,i)\n",
    "        child_item = driver.find_elements_by_xpath((f'({base_xpath})[{i+1}]{bold_tags_xpath}'))\n",
    "        child_item_text = get_text_from_element_list(child_item)\n",
    "        city= get_city_list(child_item_text,parent_items[i].text,city,0)\n",
    "        country = get_elements_from_list(driver,country_xpath,base_xpath,country,i)\n",
    "        coordinates =  get_coordinates_list(child_item_text,parent_items[i].text,coordinates,1)\n",
    "        date = get_elements_from_list(driver,date_xpath,base_xpath,date,i)\n",
    "        times = get_elements_from_list(driver,time_xpath,base_xpath,times,i)\n",
    "        scale_elements_list = driver.find_elements_by_xpath((f'{scale_xpath_1}[{i+1}]{scale_xpath_2} | {scale_xpath_3}[{i+1}]{scale_xpath_4}'))\n",
    "        scale = get_scale_list(scale,scale_elements_list)\n",
    "        length = get_len_list(child_item_text,parent_items[i].text,length,1,len_elements[i])\n",
    "    return district, city, country, coordinates, date, times, scale,length,years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilary functions in charge of initial parsing and cleaning of the data captured by XPATH\n",
    "def replace_child_text(child_text,field):\n",
    "    for word in child_text.split(' '):\n",
    "        field = field.replace('\\n','').replace(word,'',1).lstrip()\n",
    "    return field\n",
    "\n",
    "def checks_split_position(field,selector):\n",
    "    if field[0] == '(':\n",
    "        selector = selector + 1\n",
    "    return selector\n",
    "\n",
    "def checks_digit(field,selector):\n",
    "    return field.split('(')[selector][0].isdigit()\n",
    "\n",
    "def checks_len(field):\n",
    "    return '<' in field\n",
    "    \n",
    "def get_text_from_element_list(elem_list):\n",
    "    text = ''\n",
    "    for elem in elem_list:\n",
    "        text += elem.text + ' '\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilary functions to clean the data further and appending it to the relevant lists\n",
    "def append_coordinates_list(field,curr_list,position):\n",
    "    if checks_len(field):\n",
    "        curr_list.append(field.split('(')[position].split(')')[0].rstrip())\n",
    "    else:\n",
    "        curr_list.append(field.split('(')[position].rstrip().replace(')',''))\n",
    "    return curr_list\n",
    "\n",
    "def get_coordinates_list(child_text,field,curr_list,selector):\n",
    "    field = replace_child_text(child_text,field)\n",
    "    position = checks_split_position(field, selector)\n",
    "    if checks_digit(field,position):\n",
    "            curr_list = append_coordinates_list(field,curr_list,position)\n",
    "    else:\n",
    "        if checks_digit(field,position-1):\n",
    "            curr_list = append_coordinates_list(field,curr_list,position-1)\n",
    "        else:\n",
    "            curr_list.append(np.nan)\n",
    "    return curr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilary functions to clean the data further and appending it to the relevant lists\n",
    "'''if the size of the elements list is 1 it gets only \"tornado\" dummy text, so there is no scale in the text, otherwise there is scale \n",
    "in the text so take the relevant F scale'''\n",
    "def get_scale_list(scale,scale_elements_list):\n",
    "    if len(scale_elements_list) == 1:\n",
    "        scale.append(np.nan)\n",
    "    else:\n",
    "        for element in scale_elements_list:\n",
    "            if 'F' in element.text:\n",
    "                scale.append(element.text)\n",
    "    return scale\n",
    "'''if there's a field in the right textbox with specified path length get the number presented in it, otherwise check if the first char is a digit, if so check if the field on the left \n",
    "    has the \"<\" char, which indicates length, if so take it, otherwise input nan in the list'''\n",
    "def get_len_list(child_text,field,curr_list,selector,element):\n",
    "    if 'path length:' in element.text:\n",
    "        curr_list.append(element.text.split('path length:')[1].split('k')[0].strip()) \n",
    "    else:\n",
    "        field = replace_child_text(child_text,field)\n",
    "        if checks_digit(field,selector):\n",
    "            if checks_len(field):\n",
    "                curr_list.append(field.split('<')[1].split('k')[0].strip()) \n",
    "            else:\n",
    "                curr_list.append(np.nan)\n",
    "        else:\n",
    "            curr_list.append(np.nan)\n",
    "    return curr_list\n",
    "'''if the first character is a digit put nan, otherwise take the city name'''\n",
    "def get_city_list(child_text,field,curr_list,selector):\n",
    "    field = replace_child_text(child_text,field)\n",
    "    position = checks_split_position(field, selector)\n",
    "    if checks_digit(field,position):\n",
    "        curr_list.append(np.nan)\n",
    "    else:\n",
    "        curr_list.append(field.split('(')[position].rstrip().replace(')',''))\n",
    "    return curr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxilary functions to input bold text to the relevant lists and create a df using the lists\n",
    "def get_elements_from_list(driver,curr_xpath,base_xpath,curr_list,i):\n",
    "    curr_list.append(driver.find_elements_by_xpath((base_xpath+curr_xpath))[i].text)\n",
    "    return curr_list\n",
    "\n",
    "def get_df_from_lists(district, city, country, coordinates, date, times, scale,length,year):\n",
    "    df = pd.DataFrame({'district':district,'city':city,'country':country,'coordinates':coordinates,'date':date,'time':times,'scale':scale,'length (km)':length,'year':year})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to crawl the data from the website and create a df\n",
    "driver = create_web_driver()\n",
    "start_web_driver(driver,ESWD_URL)\n",
    "driver.find_element_by_xpath(ESWD_TORNADO_XPATH).click()\n",
    "district, city, country, coordinates, date, times, scale,length,years = [], [], [], [], [], [], [], [],[]\n",
    "for year in YEARS_TO_COUNT:\n",
    "    for month in MONTHS_TO_COUNT:\n",
    "        end_date = get_end_date(year,month)\n",
    "        start_date = get_start_date(year, month)\n",
    "        input_date(driver, start_date, end_date,START_DATE_XPATH,END_DATE_XPATH)\n",
    "        driver.find_element_by_xpath(SUBMIT_XPATH).click()\n",
    "        reports_amount = driver.find_element_by_xpath(FIND_REPORTS_COUNT_XPATH).text\n",
    "        log(f'{year}-{month}-{reports_amount}', 'amount_of_reports.log')\n",
    "        if \"no report\" in reports_amount:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "        district, city, country, coordinates, date, times, scale,length,years = get_data_from_page(driver,year,district, city, country, coordinates, date, times, scale,length,years)\n",
    "        edf = get_df_from_lists(district, city, country, coordinates, date, times, scale,length,years)\n",
    "edf.to_csv(f'ESWD_data.csv')\n",
    "close_web_driver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
